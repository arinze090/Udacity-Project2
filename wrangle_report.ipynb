{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c38caf08",
   "metadata": {},
   "source": [
    "## Report on Wrangled Data Collected For The Purpose of Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90c46e5",
   "metadata": {},
   "source": [
    "The wrangled dataset is that of a tweet archive of twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a twitter account that rates people's dogs with a humorous comment about the dog. The dataset that was gathered are in three pieces, we have the twitter archived_enhanced csv file, the image-prediction tsv file and an additional data from twitter api. After importing all the neccesary libraries the twitter archived_enhanced csv file was downloaded directly and loaded into a dataframe named df_archive with 2356 rows and 17 columns, the attribute of each row consist but not limited to the following tweet_id, timestamp, source, which indicates the platform the tweet was sent from, and text as the content of the tweet, some other attributes include rating_numerator, rating_denominator and name. The doggo, floofer, pupper, puppo attributes represent the dog stages. For the second piece of data the Requests library was used to download the tweet image prediction tsv file, the response from the request was converted to a string and encoded with utf-8 before loading the tsv file into a dataframe named df_pred with 2075 rows and 12 columns, the attributes of each row contain tweet_id, jpg_url, img_num as the number of predicted images, p1 as first prediction, p2 as second prediction, p3 as third prediction and many more. The third piece of data could be gathered via the Twitter API; twitter did not approve my reguest for api keys and authentication, I downloaded the data from the tweet-json text url into directory into which the json text file would be written. Each tweet's JSON data was written to its own line. I extracted the tweet_id, retweet_count and favorite_count from the response and appended it to an empty list before passing the list to a dataframe named df_json which has 2354 rows and 3 columns, the attributes of the row are tweet_id, retweet_count and favorite_count.\n",
    "\n",
    "While assessing the three dataframes both visually and programmatically for cleaning, a number of quality and tidiness issues were encountered and documented below;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f736cd0",
   "metadata": {},
   "source": [
    "## Quality Issues\n",
    "\n",
    "1. Name column in twitter_archive_df dataframe contains some invalid records example \"None\"\n",
    "\n",
    "2. The values in column named source in twitter_archive_df should explicitly state the name of the platform the tweet was sent from, this would be replaced from html tag to the source name.\n",
    "\n",
    "3. Five Columns in twitter_archive_df have more than 70% null values would be dropped, the columns affected are in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id,  retweeted_status_timestamp.  \n",
    "\n",
    "4. The dog with no stage value in the doggo, floofer, pupper and puppo columns should be explicitly stated as np.nan before merging the columns to a single colmn dog stage.\n",
    "\n",
    "5. The column tweet_id data type should have proper data type and as such would be change from int to string in all the dataframes.\n",
    "\n",
    "6. The column timestamp column in the twitter archive dataframe should be converted from object data type to datetime, the columns source and name  in the archive dataframe would be converted from object data type to string.\n",
    "\n",
    "7. The img_num column in the image prediction dataframe image number that corresponded to the most confident prediction (numbered 1 to 4 since tweets can have up to four images), this would be converted from int to categorical variable.\n",
    "\n",
    "8. p1, p1_conf, p1_dog, p2, p2_conf, p2_dog, p3, p3_conf, and p3_dog column labels in the image prediction dataframe should have a clear and precise meaning, these labels would be replaced.\n",
    "\n",
    "9. The df_archive text column contain the main tweet, ratings and the tweet's link which would be split into different columns.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Tidiness issues\n",
    "1. There are multiple dog stages columns present i.e. doggo, floofer, pupper and puppo. each observation should form a row, merging the columns to a single dog stage column would solve the issue, lastly the four dog stage columns would be dropped .\n",
    "\n",
    "2. All the three datasets are part of same observational unit, merging 3 tables into one will done to tidy up the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6576395",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
